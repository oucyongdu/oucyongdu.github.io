<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Yong Du&#39;s Homepage</title>
    <meta name="description" content="Yong Du&#39;s Homepage">
    <link rel="icon" href="/headlogo.png">
    
    <link rel="preload" href="/assets/css/0.styles.4aa2bec9.css" as="style"><link rel="preload" href="/assets/js/app.f1cc3754.js" as="script"><link rel="preload" href="/assets/js/3.1d9540bd.js" as="script"><link rel="preload" href="/assets/js/17.d835eb1d.js" as="script"><link rel="preload" href="/assets/js/11.86f09cba.js" as="script"><link rel="prefetch" href="/assets/js/1.6d469650.js"><link rel="prefetch" href="/assets/js/10.6b6bda37.js"><link rel="prefetch" href="/assets/js/12.aed98a47.js"><link rel="prefetch" href="/assets/js/13.7d4a7d2d.js"><link rel="prefetch" href="/assets/js/14.4876f813.js"><link rel="prefetch" href="/assets/js/15.9c2415f5.js"><link rel="prefetch" href="/assets/js/16.e348bd59.js"><link rel="prefetch" href="/assets/js/18.6b3815ab.js"><link rel="prefetch" href="/assets/js/19.0a31b4fe.js"><link rel="prefetch" href="/assets/js/20.4704cbda.js"><link rel="prefetch" href="/assets/js/4.dd95573b.js"><link rel="prefetch" href="/assets/js/5.d9ee0eab.js"><link rel="prefetch" href="/assets/js/6.0b2b6e2a.js"><link rel="prefetch" href="/assets/js/7.844f1cfe.js"><link rel="prefetch" href="/assets/js/8.dfb8a44a.js"><link rel="prefetch" href="/assets/js/9.796e6f5c.js">
    <link rel="stylesheet" href="/assets/css/0.styles.4aa2bec9.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar projects-page"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/logo.png" alt="Yong Du's Homepage" class="logo"> <span class="site-name can-hide">Yong Du's Homepage</span></a> <div class="links"><!----> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/publications/" class="nav-link router-link-exact-active router-link-active">Publications</a></div><div class="nav-item"><a href="/group/" class="nav-link">Group</a></div><div class="nav-item"><a href="/teaching/" class="nav-link">Teaching</a></div><div class="nav-item"><a href="/contact/" class="nav-link">Contact</a></div> <!----></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link">Home</a></div><div class="nav-item"><a href="/publications/" class="nav-link router-link-exact-active router-link-active">Publications</a></div><div class="nav-item"><a href="/group/" class="nav-link">Group</a></div><div class="nav-item"><a href="/teaching/" class="nav-link">Teaching</a></div><div class="nav-item"><a href="/contact/" class="nav-link">Contact</a></div> <!----></nav>  <!----> </aside> <main class="page"> <div class="theme-default-content content__default"><p style="position:relative;"><font size="4"><sup>#</sup>Joint first author, *Corresponding author.</font></p> <h2 id="_2025">2025</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/ICCV25-VTON.jpg" alt></div> <div class="card-content"><p><strong>OmniVTON: Training-Free Universal Virtual Try-On</strong></p> <p><em>Zhaotong Yang, Yuhui Li, Shengfeng He, Xinzhe Li, Yangyang Xu, Junyu Dong, and <strong>Yong Du*</strong></em></p> <p>International Conference on Computer Vision (<strong>ICCV</strong>), 2025</p> <p>[<a href="https://arxiv.org/abs/2507.15037" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/Jerome-Young/OmniVTON" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/ICCV25-BAI.jpg" alt></div> <div class="card-content"><p><strong>Cross-Subject Mind Decoding from Inaccurate Representations</strong></p> <p><em>Yangyang Xu, Bangzhen Liu, Wenqi Shao, <strong>Yong Du*</strong>, Shengfeng He, and Tingting Zhu</em></p> <p>International Conference on Computer Vision (<strong>ICCV</strong>), 2025</p> <p>[<a href="https://arxiv.org/abs/2507.19071" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://www.csyongdu.cn/publications/" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/ICCV25-SSD.jpg" alt></div> <div class="card-content"><p><strong>Stable Score Distillation</strong></p> <p><em>Haiming Zhu, Yangyang Xu, Chenshu Xu, Tingrui Shen, Wenxi Liu, <strong>Yong Du</strong>, Jun Yu, and Shengfeng He</em></p> <p>International Conference on Computer Vision (<strong>ICCV</strong>), 2025</p> <p>[<a href="https://arxiv.org/abs/2507.09168" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://www.csyongdu.cn/publications/" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/CVPR2025.jpg" alt></div> <div class="card-content"><p><strong>NexusGS: Sparse View Synthesis with Epipolar Depth Priors in 3D Gaussian Splatting</strong></p> <p><em>Yulong Zheng, Zicheng Jiang, Shengfeng He, Yandu Sun, Junyu Dong, Huaidong Zhang, and <strong>Yong Du*</strong></em></p> <p>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2025</p> <p><span style="font-size:15px;color:rgb(226, 80, 65);">(Highlight Paper, Top 2.98% of all submissions)</span></p> <p>[<a href="https://arxiv.org/abs/2503.18794" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://usmizuki.github.io/NexusGS/" target="_blank" rel="noopener noreferrer">Project Page<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://www.youtube.com/watch?v=K2foTIXzpMQ" target="_blank" rel="noopener noreferrer">Demo<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/TPAMI2025.jpg" alt></div> <div class="card-content"><p><strong>One-for-All: Towards Universal Domain Translation with a Single StyleGAN</strong></p> <p><em><strong>Yong Du<sup>#</sup>*</strong>, Jiahui Zhan<sup>#</sup>, Xinzhe Li, Junyu Dong, Sheng Chen, Ming-Hsuan Yang, and Shengfeng He</em></p> <p>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2025</p> <p>[<a href="https://arxiv.org/pdf/2310.14222" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://zhanjiahui.github.io/UniTranslator/" target="_blank" rel="noopener noreferrer">Project Page<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://www.youtube.com/watch?v=_VTF9-U7V3g" target="_blank" rel="noopener noreferrer">Demo<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/AAAI2025.jpg" alt></div> <div class="card-content"><p><strong>PersonaMagic: Stage-Regulated High-Fidelity Face Customization with Tandem Equilibrium</strong></p> <p><em>Xinzhe Li, Jiahui Zhan, Shengfeng He, Yangyang Xu, Junyu Dong, Huaidong Zhang, and <strong>Yong Du*</strong></em></p> <p>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2025</p> <p>[<a href="https://arxiv.org/pdf/2412.15674" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/xzhe-Vision/PersonaMagic" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/MM2025.jpg" alt></div> <div class="card-content"><p><strong>DiffusionMat: Alpha Matting as Deterministic Sequential Refinement Learning</strong></p> <p><em>Yangyang Xu, Shengfeng He, Wenqi Shao, <strong>Yong Du</strong>, Kwan-Yee K. Wong, Yu Qiao, Jun Yu, and Ping Luo</em></p> <p>ACM International Conference on Multimedia (<strong>ACM MM</strong>), 2025</p> <p>[<a href="https://www.csyongdu.cn/publications/" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://www.csyongdu.cn/publications/" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/TVCG2025.jpg" alt></div> <div class="card-content"><p><strong>StyleGAN-âˆž: Extending StyleGAN to Arbitrary-Ratio Translation with StyleBook</strong></p> <p><em>Yihua Dai, Tianyi Xiang, Bailin Deng, <strong>Yong Du</strong>, Hongmin Cai, Jing Qin, and Shengfeng He</em></p> <p>IEEE Transactions on Visualization and Computer Graphics (<strong>TVCG</strong>), 2025</p> <p>[<a href="https://ieeexplore.ieee.org/document/10816137" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://www.csyongdu.cn/publications/" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p><strong>SITA: Structurally Imperceptible and Transferable Adversarial Attacks for Stylized Image Generation</strong></p> <p><em>Jingdan Kang, Haoxin Yang, Yan Cai, Huaidong Zhang, Xuemiao Xu, <strong>Yong Du</strong>, and Shengfeng He</em></p> <p>IEEE Transactions on Information Forensics and Security (<strong>TIFS</strong>), 2025</p> <p>[<a href="https://ieeexplore.ieee.org/document/10943240/" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/A-raniy-day/SITA" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="_2024">2024</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/ECCV2024.jpg" alt></div> <div class="card-content"><p><strong>D<sup>4</sup>-VTON: Dynamic Semantics Disentangling for Differential Diffusion based Virtual Try-On</strong></p> <p><em>Zhaotong Yang, Zicheng Jiang, Xinzhe Li, Huiyu Zhou, Junyu Dong, Huaidong Zhang, and <strong>Yong Du*</strong></em></p> <p>European Conference on Computer Vision (<strong>ECCV</strong>), 2024</p> <p>[<a href="https://arxiv.org/pdf/2407.15111" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/Jerome-Young/D4-VTON" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/CVPR2024.jpg" alt></div> <div class="card-content"><p><strong>D3still: Decoupled Differential Distillation for Asymmetric Image Retrieval</strong></p> <p><em>Yi Xie, Yihong Lin, Wenjie Cai, Xuemiao Xu, Huaidong Zhang, <strong>Yong Du</strong>, and Shengfeng He</em></p> <p>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024</p> <p>[<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xie_D3still_Decoupled_Differential_Distillation_for_Asymmetric_Image_Retrieval_CVPR_2024_paper.pdf" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/SCY-X/D3still" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p><strong>Enhancing Generalized Zero-shot Learning with Dynamic Selective Knowledge Distillation</strong></p> <p><em>Weihua Lv, Yulong Zheng, Chao Liu, and <strong>Yong Du*</strong></em></p> <p>International Conference on Wireless Artificial Intelligent Computing Systems and Applications (WASA), 2024</p> <p>[<a href="https://www.csyongdu.cn/publications/" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="_2023">2023</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/CVPR2023.jpg" alt></div> <div class="card-content"><p><strong>Curricular Contrastive Regularization for Physics-aware Single Image Dehazing</strong></p> <p><em>Yu Zheng, Jiahui Zhan, Shengfeng He, Junyu Dong, and <strong>Yong Du*</strong></em></p> <p>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</p> <p>[<a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zheng_Curricular_Contrastive_Regularization_for_Physics-Aware_Single_Image_Dehazing_CVPR_2023_paper.pdf" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://openaccess.thecvf.com/content/CVPR2023/supplemental/Zheng_Curricular_Contrastive_Regularization_CVPR_2023_supplemental.pdf" target="_blank" rel="noopener noreferrer">Supp<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/YuZheng9/C2PNet" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/CVIU2023.jpg" alt></div> <div class="card-content"><p><strong>DSDNet: Toward Single Image Deraining with Self-paced Curricular Dual Stimulations</strong></p> <p><em><strong>Yong Du</strong>, Junjie Deng, Yulong Zheng, Junyu Dong, and Shengfeng He</em></p> <p>Computer Vision and Image Understanding (<strong>CVIU</strong>), 2023</p> <p>[<a href="https://www.sciencedirect.com/science/article/pii/S1077314223000371?dgcid=author" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="_2022">2022</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/ECCV2022.jpg" alt></div> <div class="card-content"><p><strong>Editing Out-of-domain GAN Inversion via Differential Activations</strong></p> <p><em>Haorui Song<sup>#</sup>, <strong>Yong Du<sup>#</sup></strong>, Tianyi Xiang, Junyu Dong, Jing Qin, and Shengfeng He</em></p> <p>European Conference on Computer Vision (<strong>ECCV</strong>), 2022</p> <p>[<a href="https://arxiv.org/abs/2207.08134" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://www.youtube.com/watch?v=aEM6mah60lc" target="_blank" rel="noopener noreferrer">Video Demo<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/HaoruiSong622/Editing-Out-of-Domain" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/TIP2022.jpg" alt></div> <div class="card-content"><p><strong>Pro-PULSE: Learning Progressive Encoders of Latent Semantics in GANs for Photo Upsampling</strong></p> <p><em>Yang Zhou, Yangyang Xu, <strong>Yong Du</strong>, Qiang Wen,  and Shengfeng He</em></p> <p>IEEE Transactions on Image Processing (<strong>TIP</strong>), 2022</p> <p>[<a href="https://ieeexplore.ieee.org/document/9678071" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/youngAt19/Pro-PULSE" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p><strong>Delving Deep into Pixelized Face Recovery and Defense</strong></p> <p><em>Zhixuan Zhong, <strong>Yong Du</strong>, Yang Zhou, Jiangzhong Cao, and Shengfeng He</em></p> <p>Neurocomputing, 2022</p> <p>[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231222012395" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="_2021">2021</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/ICCV2021.jpg" alt></div> <div class="card-content"><p><strong>From Continuity to Editability: Inverting GANs with Consecutive Images</strong></p> <p><em>Yangyang Xu, <strong>Yong Du</strong>, Wenpeng Xiao, Xuemiao Xu, and Shengfeng He</em></p> <p>IEEE International Conference on Computer Vision (<strong>ICCV</strong>), 2021</p> <p>[<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Xu_From_Continuity_to_Editability_Inverting_GANs_With_Consecutive_Images_ICCV_2021_paper.pdf" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://openaccess.thecvf.com/content/ICCV2021/supplemental/Xu_From_Continuity_to_ICCV_2021_supplemental.pdf" target="_blank" rel="noopener noreferrer">Supp<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/Qingyang-Xu/InvertingGANs_with_ConsecutiveImgs" target="_blank" rel="noopener noreferrer">Code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/CVPR2021.jpg" alt></div> <div class="card-content"><p><strong>Learning from the Master: Distilling Cross-modal Advanced Knowledge for Lip Reading</strong></p> <p><em>Sucheng Ren<sup>#</sup>, <strong>Yong Du<sup>#</sup></strong>, Jianming Lv, Guoqiang Han,  and Shengfeng He</em></p> <p>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2021</p> <p>[<a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Ren_Learning_From_the_Master_Distilling_Cross-Modal_Advanced_Knowledge_for_Lip_CVPR_2021_paper.pdf" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/TOMM2021.jpg" alt></div> <div class="card-content"><p><strong>Invertible Grayscale with Sparsity Enforcing Priors</strong></p> <p><em><strong>Yong Du</strong>, Yangyang Xu, Taizhong Ye, Qiang Wen, Chufeng Xiao, Junyu Dong, Guoqiang Han, and Shengfeng He</em></p> <p>ACM Transactions on Multimedia Computing, Communications, and Applications (<strong>TOMM</strong>), 2021</p> <p>[<a href="https://dl.acm.org/doi/10.1145/3451993" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p><strong>Mask-ShadowNet: Toward Shadow Removal via Masked Adaptive Instance Normalization</strong></p> <p><em>Shengfeng He, Bing Peng, Junyu Dong, and <strong>Yong Du*</strong></em></p> <p>IEEE Signal Processing Letters (SPL), 2021</p> <p>[<a href="https://ieeexplore.ieee.org/document/9408351" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p><strong>Fast Scene Labeling via Structural Inference</strong></p> <p><em>Huaidong Zhang, Chu Han, Xiaodan Zhang, <strong>Yong Du</strong>, Xuemiao Xu, Guoqiang Han, Jing Qin, and Shengfeng He</em></p> <p>Neurocomputing, 2021</p> <p>[<a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221003428" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p><strong>TPRDTVN: A Routing Algorithm in Delay Tolerant Vessel Network based on Long-term Trajectory Prediction</strong></p> <p><em>Chao Liu, Yingbin Li, Ruobing Jiang, <strong>Yong Du*</strong>, Qian Lu, and Zhongwen Guo</em></p> <p>Wireless Communications and Mobile Computing (WCMC), 2021</p> <p>[<a href="https://www.hindawi.com/journals/wcmc/2021/6630265/" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="_2020">2020</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/TMM2020.jpg" alt></div> <div class="card-content"><p><strong>Blind Image Denoising via Dynamic Dual Learning</strong></p> <p><em><strong>Yong Du</strong>, Guoqiang Han, Yinjie Tan, Chufeng Xiao, and Shengfeng He</em></p> <p>IEEE Transactions on Multimedia (<strong>TMM</strong>), 2020</p> <p>[<a href="https://ieeexplore.ieee.org/document/9136787" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><div class="card-image"><img src="/projects/TIP2020.jpg" alt></div> <div class="card-content"><p><strong>Real-time Hierarchical Supervoxel Segmentation via a Minimum Spanning Tree</strong></p> <p><em>Bo Wang, Yiliang Chen, Wenxi Liu, Jing Qin, <strong>Yong Du</strong>, Guoqiang Han, and Shengfeng He</em></p> <p>IEEE Transactions on Image Processing (<strong>TIP</strong>), 2020</p> <p>[<a href="https://ieeexplore.ieee.org/document/9229239" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <div class="md-card show-border"><!----> <div class="card-content"><p><strong>Invertible Grayscale via Dual Features Ensemble</strong></p> <p><em>Taizhong Ye<sup>#</sup>, <strong>Yong Du<sup>#</sup></strong>, Junjie Deng, and Shengfeng He</em></p> <p>IEEE Access, 2020</p> <p>[<a href="https://ieeexplore.ieee.org/document/9091800" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div> <h2 id="before-2019">Before 2019</h2> <div class="md-card show-border"><div class="card-image"><img src="/projects/TCYB2019.jpg" alt></div> <div class="card-content"><p><strong>Exploiting Global Low-rank Structure and Local Sparsity Nature for Tensor Completion</strong></p> <p><em><strong>Yong Du</strong>, Guoqiang Han, Yuhui Quan, Zhiwen Yu, Hau-San Wong, C.L.Philip Chen, and Jun Zhang</em></p> <p>IEEE Transactions on Cybernetics (<strong>TCYB</strong>), 2019</p> <p>[<a href="https://ieeexplore.ieee.org/document/8418828" target="_blank" rel="noopener noreferrer">PDF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>] [<a href="https://github.com/csyongdu/Exploiting-Global-Low-Rank-Structure-and-Local-Sparsity-Nature-for-Tensor-Completion" target="_blank" rel="noopener noreferrer">code<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>]</p></div></div></div> <footer class="page-edit"><!----> <!----></footer> <!----> </main></div><div class="global-ui"></div></div>
    <script src="/assets/js/app.f1cc3754.js" defer></script><script src="/assets/js/3.1d9540bd.js" defer></script><script src="/assets/js/17.d835eb1d.js" defer></script><script src="/assets/js/11.86f09cba.js" defer></script>
  </body>
</html>
